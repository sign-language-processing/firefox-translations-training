[2022-07-06 17:37:47] [marian] Marian v1.10.25; e8a1a253 2021-12-07 17:47:33 +0000
[2022-07-06 17:37:47] [marian] Running on mlc4 as process 37 with command line:
[2022-07-06 17:37:47] [marian] /data/rw/evgeny/firefox-translations-training/3rd_party/marian-dev/build/marian-decoder -c /data/rw/evgeny/models/en-nl/prod/teacher-finetuned1/final.model.npz.best-chrf.npz.decoder.yml --quiet --quiet-translation --log /data/rw/evgeny/models/en-nl/prod/evaluation/teacher-finetuned1/mtdata_Neulab-tedtalks_test-1-eng-nld.log -w 8000 --devices 0 1 2 3 4 5 6 7 -m /data/rw/evgeny/models/en-nl/prod/teacher-finetuned1/final.model.npz.best-chrf.npz
[2022-07-06 17:37:47] [config] alignment: ""
[2022-07-06 17:37:47] [config] allow-special: false
[2022-07-06 17:37:47] [config] allow-unk: false
[2022-07-06 17:37:47] [config] authors: false
[2022-07-06 17:37:47] [config] beam-size: 8
[2022-07-06 17:37:47] [config] bert-class-symbol: "[CLS]"
[2022-07-06 17:37:47] [config] bert-mask-symbol: "[MASK]"
[2022-07-06 17:37:47] [config] bert-masking-fraction: 0.15
[2022-07-06 17:37:47] [config] bert-sep-symbol: "[SEP]"
[2022-07-06 17:37:47] [config] bert-train-type-embeddings: true
[2022-07-06 17:37:47] [config] bert-type-vocab-size: 2
[2022-07-06 17:37:47] [config] best-deep: false
[2022-07-06 17:37:47] [config] build-info: ""
[2022-07-06 17:37:47] [config] check-nan: false
[2022-07-06 17:37:47] [config] cite: false
[2022-07-06 17:37:47] [config] cpu-threads: 0
[2022-07-06 17:37:47] [config] dec-cell: gru
[2022-07-06 17:37:47] [config] dec-cell-base-depth: 2
[2022-07-06 17:37:47] [config] dec-cell-high-depth: 1
[2022-07-06 17:37:47] [config] dec-depth: 6
[2022-07-06 17:37:47] [config] devices:
[2022-07-06 17:37:47] [config]   - 0
[2022-07-06 17:37:47] [config]   - 1
[2022-07-06 17:37:47] [config]   - 2
[2022-07-06 17:37:47] [config]   - 3
[2022-07-06 17:37:47] [config]   - 4
[2022-07-06 17:37:47] [config]   - 5
[2022-07-06 17:37:47] [config]   - 6
[2022-07-06 17:37:47] [config]   - 7
[2022-07-06 17:37:47] [config] dim-emb: 1024
[2022-07-06 17:37:47] [config] dim-rnn: 1024
[2022-07-06 17:37:47] [config] dim-vocabs:
[2022-07-06 17:37:47] [config]   - 32000
[2022-07-06 17:37:47] [config]   - 32000
[2022-07-06 17:37:47] [config] dump-config: ""
[2022-07-06 17:37:47] [config] enc-cell: gru
[2022-07-06 17:37:47] [config] enc-cell-depth: 1
[2022-07-06 17:37:47] [config] enc-depth: 6
[2022-07-06 17:37:47] [config] enc-type: bidirectional
[2022-07-06 17:37:47] [config] factors-combine: sum
[2022-07-06 17:37:47] [config] factors-dim-emb: 0
[2022-07-06 17:37:47] [config] gemm-type: float32
[2022-07-06 17:37:47] [config] ignore-model-config: false
[2022-07-06 17:37:47] [config] input:
[2022-07-06 17:37:47] [config]   - stdin
[2022-07-06 17:37:47] [config] input-types:
[2022-07-06 17:37:47] [config]   []
[2022-07-06 17:37:47] [config] interpolate-env-vars: false
[2022-07-06 17:37:47] [config] layer-normalization: false
[2022-07-06 17:37:47] [config] lemma-dependency: ""
[2022-07-06 17:37:47] [config] lemma-dim-emb: 0
[2022-07-06 17:37:47] [config] log: /data/rw/evgeny/models/en-nl/prod/evaluation/teacher-finetuned1/mtdata_Neulab-tedtalks_test-1-eng-nld.log
[2022-07-06 17:37:47] [config] log-level: info
[2022-07-06 17:37:47] [config] log-time-zone: ""
[2022-07-06 17:37:47] [config] max-length: 1000
[2022-07-06 17:37:47] [config] max-length-crop: false
[2022-07-06 17:37:47] [config] max-length-factor: 3
[2022-07-06 17:37:47] [config] maxi-batch: 100
[2022-07-06 17:37:47] [config] maxi-batch-sort: src
[2022-07-06 17:37:47] [config] mini-batch: 8
[2022-07-06 17:37:47] [config] mini-batch-words: 0
[2022-07-06 17:37:47] [config] models:
[2022-07-06 17:37:47] [config]   - /data/rw/evgeny/models/en-nl/prod/teacher-finetuned1/final.model.npz.best-chrf.npz
[2022-07-06 17:37:47] [config] n-best: false
[2022-07-06 17:37:47] [config] no-spm-decode: false
[2022-07-06 17:37:47] [config] normalize: 1
[2022-07-06 17:37:47] [config] num-devices: 0
[2022-07-06 17:37:47] [config] optimize: false
[2022-07-06 17:37:47] [config] output: stdout
[2022-07-06 17:37:47] [config] output-approx-knn:
[2022-07-06 17:37:47] [config]   []
[2022-07-06 17:37:47] [config] output-omit-bias: false
[2022-07-06 17:37:47] [config] output-sampling: false
[2022-07-06 17:37:47] [config] precision:
[2022-07-06 17:37:47] [config]   - float32
[2022-07-06 17:37:47] [config] quantize-range: 0
[2022-07-06 17:37:47] [config] quiet: true
[2022-07-06 17:37:47] [config] quiet-translation: true
[2022-07-06 17:37:47] [config] relative-paths: false
[2022-07-06 17:37:47] [config] right-left: false
[2022-07-06 17:37:47] [config] seed: 0
[2022-07-06 17:37:47] [config] shortlist:
[2022-07-06 17:37:47] [config]   []
[2022-07-06 17:37:47] [config] skip: false
[2022-07-06 17:37:47] [config] skip-cost: false
[2022-07-06 17:37:47] [config] stat-freq: 0
[2022-07-06 17:37:47] [config] tied-embeddings: false
[2022-07-06 17:37:47] [config] tied-embeddings-all: true
[2022-07-06 17:37:47] [config] tied-embeddings-src: false
[2022-07-06 17:37:47] [config] transformer-aan-activation: swish
[2022-07-06 17:37:47] [config] transformer-aan-depth: 2
[2022-07-06 17:37:47] [config] transformer-aan-nogate: false
[2022-07-06 17:37:47] [config] transformer-decoder-autoreg: self-attention
[2022-07-06 17:37:47] [config] transformer-depth-scaling: false
[2022-07-06 17:37:47] [config] transformer-dim-aan: 2048
[2022-07-06 17:37:47] [config] transformer-dim-ffn: 4096
[2022-07-06 17:37:47] [config] transformer-ffn-activation: relu
[2022-07-06 17:37:47] [config] transformer-ffn-depth: 2
[2022-07-06 17:37:47] [config] transformer-guided-alignment-layer: last
[2022-07-06 17:37:47] [config] transformer-heads: 16
[2022-07-06 17:37:47] [config] transformer-no-projection: false
[2022-07-06 17:37:47] [config] transformer-pool: false
[2022-07-06 17:37:47] [config] transformer-postprocess: dan
[2022-07-06 17:37:47] [config] transformer-postprocess-emb: d
[2022-07-06 17:37:47] [config] transformer-postprocess-top: ""
[2022-07-06 17:37:47] [config] transformer-preprocess: ""
[2022-07-06 17:37:47] [config] transformer-tied-layers:
[2022-07-06 17:37:47] [config]   []
[2022-07-06 17:37:47] [config] transformer-train-position-embeddings: false
[2022-07-06 17:37:47] [config] tsv: false
[2022-07-06 17:37:47] [config] tsv-fields: 0
[2022-07-06 17:37:47] [config] type: transformer
[2022-07-06 17:37:47] [config] ulr: false
[2022-07-06 17:37:47] [config] ulr-dim-emb: 0
[2022-07-06 17:37:47] [config] ulr-trainable-transformation: false
[2022-07-06 17:37:47] [config] version: v1.10.25; e8a1a253 2021-12-07 17:47:33 +0000
[2022-07-06 17:37:47] [config] vocabs:
[2022-07-06 17:37:47] [config]   - /data/rw/evgeny/models/en-nl/prod/vocab/vocab.spm
[2022-07-06 17:37:47] [config]   - /data/rw/evgeny/models/en-nl/prod/vocab/vocab.spm
[2022-07-06 17:37:47] [config] weights:
[2022-07-06 17:37:47] [config]   []
[2022-07-06 17:37:47] [config] word-penalty: 0
[2022-07-06 17:37:47] [config] word-scores: false
[2022-07-06 17:37:47] [config] workspace: 8000
[2022-07-06 17:37:47] [config] Loaded model has been created with Marian v1.10.25; e8a1a253 2021-12-07 17:47:33 +0000
[2022-07-06 17:37:47] [data] Loading SentencePiece vocabulary from file /data/rw/evgeny/models/en-nl/prod/vocab/vocab.spm
[2022-07-06 17:37:47] [data] Loading SentencePiece vocabulary from file /data/rw/evgeny/models/en-nl/prod/vocab/vocab.spm
[2022-07-06 17:37:49] [memory] Extending reserved space to 8064 MB (device gpu3)
[2022-07-06 17:37:49] [memory] Extending reserved space to 8064 MB (device gpu5)
[2022-07-06 17:37:50] [memory] Extending reserved space to 8064 MB (device gpu2)
[2022-07-06 17:37:50] [memory] Extending reserved space to 8064 MB (device gpu7)
[2022-07-06 17:37:50] Loading scorer of type transformer as feature F0
[2022-07-06 17:37:50] Loading scorer of type transformer as feature F0
[2022-07-06 17:37:50] Loading model from /data/rw/evgeny/models/en-nl/prod/teacher-finetuned1/final.model.npz.best-chrf.npz
[2022-07-06 17:37:50] Loading model from /data/rw/evgeny/models/en-nl/prod/teacher-finetuned1/final.model.npz.best-chrf.npz
[2022-07-06 17:37:50] [memory] Extending reserved space to 8064 MB (device gpu6)
[2022-07-06 17:37:50] Loading scorer of type transformer as feature F0
[2022-07-06 17:37:50] Loading model from /data/rw/evgeny/models/en-nl/prod/teacher-finetuned1/final.model.npz.best-chrf.npz
[2022-07-06 17:37:50] [memory] Extending reserved space to 8064 MB (device gpu0)
[2022-07-06 17:37:50] Loading scorer of type transformer as feature F0
[2022-07-06 17:37:50] Loading model from /data/rw/evgeny/models/en-nl/prod/teacher-finetuned1/final.model.npz.best-chrf.npz
[2022-07-06 17:37:50] Loading scorer of type transformer as feature F0
[2022-07-06 17:37:50] Loading model from /data/rw/evgeny/models/en-nl/prod/teacher-finetuned1/final.model.npz.best-chrf.npz
[2022-07-06 17:37:50] [memory] Extending reserved space to 8064 MB (device gpu4)
[2022-07-06 17:37:50] Loading scorer of type transformer as feature F0
[2022-07-06 17:37:50] Loading model from /data/rw/evgeny/models/en-nl/prod/teacher-finetuned1/final.model.npz.best-chrf.npz
[2022-07-06 17:37:50] Loading scorer of type transformer as feature F0
[2022-07-06 17:37:50] Loading model from /data/rw/evgeny/models/en-nl/prod/teacher-finetuned1/final.model.npz.best-chrf.npz
[2022-07-06 17:37:50] [memory] Extending reserved space to 8064 MB (device gpu1)
[2022-07-06 17:37:50] Loading scorer of type transformer as feature F0
[2022-07-06 17:37:50] Loading model from /data/rw/evgeny/models/en-nl/prod/teacher-finetuned1/final.model.npz.best-chrf.npz
[2022-07-06 17:37:53] [memory] Reserving 797 MB, device gpu2
[2022-07-06 17:37:53] [memory] Reserving 797 MB, device gpu1
[2022-07-06 17:37:53] [memory] Reserving 797 MB, device gpu5
[2022-07-06 17:37:53] [memory] Reserving 797 MB, device gpu3
[2022-07-06 17:37:53] [memory] Reserving 797 MB, device gpu6
[2022-07-06 17:37:53] [memory] Reserving 797 MB, device gpu7
[2022-07-06 17:37:53] [memory] Reserving 797 MB, device gpu0
[2022-07-06 17:37:53] [memory] Reserving 797 MB, device gpu4
[2022-07-06 17:37:56] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2022-07-06 17:38:19] Total time: 24.49098s wall
